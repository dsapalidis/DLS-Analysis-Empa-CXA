{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory (POSIX format): C:/Users/Dimitris/Desktop/DLLLLLS/Results\n",
      "Output directory (POSIX format): C:/Users/Dimitris/Desktop/DLLLLLS/Graphs\n",
      "Error processing file 20190603_cubA4_90_5673.txt73: [Errno 2] No such file or directory: '20190603_cubA4_90_5673.txt73'\n",
      "Error processing file 20190603_cubA4_90_5673.txt74: [Errno 2] No such file or directory: '20190603_cubA4_90_5673.txt74'\n",
      "Error processing file 20190603_cubA4_90_5673.txt75: [Errno 2] No such file or directory: '20190603_cubA4_90_5673.txt75'\n",
      "Error processing file 20190603_cubA4_90_5673.txt76: [Errno 2] No such file or directory: '20190603_cubA4_90_5673.txt76'\n",
      "Error processing file 20190603_cubA4_90_5673.txt77: [Errno 2] No such file or directory: '20190603_cubA4_90_5673.txt77'\n",
      "Error processing file 20190603_cubA4_173_5676.txt76: [Errno 2] No such file or directory: '20190603_cubA4_173_5676.txt76'\n",
      "Error processing file 20190603_cubA4_173_5676.txt77: [Errno 2] No such file or directory: '20190603_cubA4_173_5676.txt77'\n",
      "Error processing file 20190603_cubA4_173_5676.txt78: [Errno 2] No such file or directory: '20190603_cubA4_173_5676.txt78'\n",
      "Error processing file 20190603_cubA4_173_5676.txt79: [Errno 2] No such file or directory: '20190603_cubA4_173_5676.txt79'\n",
      "Error processing file 20190603_cubA4_173_5676.txt80: [Errno 2] No such file or directory: '20190603_cubA4_173_5676.txt80'\n",
      "Error fitting autocorrelation curve at 90° for idx=1: 1\n",
      "Error fitting autocorrelation curve at 90° for idx=2: 2\n",
      "Error fitting autocorrelation curve at 90° for idx=3: 3\n",
      "Error fitting autocorrelation curve at 90° for idx=4: 4\n",
      "Error fitting autocorrelation curve at 90° for idx=5: 5\n",
      "Error fitting autocorrelation curve at 173° for idx=1: 1\n",
      "Error fitting autocorrelation curve at 173° for idx=2: 2\n",
      "Error fitting autocorrelation curve at 173° for idx=3: 3\n",
      "Error fitting autocorrelation curve at 173° for idx=4: 4\n",
      "Error fitting autocorrelation curve at 173° for idx=5: 5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lsqcurvefit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7728\\3661574092.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2e-14\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnormS1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlsqcurvefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mydata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[0mfit1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxdata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lsqcurvefit' is not defined"
     ]
    }
   ],
   "source": [
    "## Dynamic Light Scattering ##\n",
    "\n",
    "## Data Analysis Process - Matlab Code converter (Version 1.1) ##\n",
    "\n",
    "## Empa, Center for X-ray Analytics, D.Sapalidis, St. Gallen, Switzerland, 28.06.2024 ##\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Measurement numbers\n",
    "j_90 = 73\n",
    "j_173 = 76\n",
    "\n",
    "# Ονόματα αρχείων μετρήσεων\n",
    "file_90 = f'20190603_cubA4_90_56{j_90}.txt'\n",
    "file_173 = f'20190603_cubA4_173_56{j_173}.txt'\n",
    "\n",
    "# Example usage of the function\n",
    "input_directory = r\"C:\\Users\\Dimitris\\Desktop\\DLLLLLS\\Results\"\n",
    "output_directory = r\"C:\\Users\\Dimitris\\Desktop\\DLLLLLS\\Graphs\"\n",
    "\n",
    "# Convert Windows paths to POSIX paths for compatibility\n",
    "input_directory = pathlib.PureWindowsPath(input_directory).as_posix()\n",
    "output_directory = pathlib.PureWindowsPath(output_directory).as_posix()\n",
    "\n",
    "\n",
    "# Print converted directories for verification\n",
    "print(\"Input directory (POSIX format):\", input_directory)\n",
    "print(\"Output directory (POSIX format):\", output_directory)\n",
    "\n",
    "\n",
    "# Discard bad results\n",
    "Discard_list = []  # Sequential order of measurements to discard for global fitting\n",
    "Discard_list_total = []  # Sequential order of measurements not to show\n",
    "\n",
    "Temperature = 25  # Example, user-defined value\n",
    "Temp_Kelvin = Temperature + 273.15\n",
    "Boltzmann = 1.38065e-23  # J.K-1, example value, user-defined\n",
    "lambda_val = 0.6328e-9  # Example, user-defined\n",
    "rIndex = 1.37  # Example, user-defined\n",
    "visc = 0.887e-3  # Example, user-defined\n",
    "\n",
    "# Options\n",
    "showPartSize = 1\n",
    "showR2 = 1\n",
    "mergeFigs = 1\n",
    "showHor = 1\n",
    "showLegd = 2\n",
    "PrintFigs = 1\n",
    "NormLz = 1\n",
    "\n",
    "# Initial guesses for fitting parameters\n",
    "x0_1 = np.array([0, 1, 200e-9, 2e-4])\n",
    "lb_1 = np.array([0, 0, 10e-9, 0])\n",
    "up_1 = np.array([2, 2, 5000e-9, 20])\n",
    "\n",
    "\n",
    "# Second fit (linear)\n",
    "x1_1 = 2e-14\n",
    "x1_2 = 2e-14\n",
    "\n",
    "# Miscellaneous\n",
    "XPicSize1 = 3\n",
    "YPicSize1 = 4\n",
    "XPicSize2 = 3\n",
    "YPicSize2 = 4\n",
    "\n",
    "# Print results function\n",
    "def print_results(FitResultsTable, mean_PDI_90, mean_PDI_173, D1, Rh1, Dh1, SE_Dh1):\n",
    "    print(\"Fit Results Table:\")\n",
    "    print(FitResultsTable)\n",
    "    print(\"Global Fit:\")\n",
    "    print(\" ' '   'diffusion / m2/s'   'Rh / nm'   'Dh / nm'   'SE Dh / nm'   'PDI 90Ί'   'PDI 173Ί'   'PDI'\")\n",
    "    print(f\" 'fast mode'   {D1}   {Rh1*10**9}   {Dh1*10**9}   {SE_Dh1*10**9}   {mean_PDI_90}   {mean_PDI_173}\")\n",
    "\n",
    "def load_measurement_data(file_pattern, j, directory):\n",
    "    measurements = []\n",
    "    for i in range(j, j + 2):\n",
    "        filename = os.path.join(directory, file_pattern.format(i))\n",
    "        try:\n",
    "            data = pd.read_csv(filename, delimiter='\\t', header=None, names=['Column1', 'Column2', 'Column3'], encoding='latin1')\n",
    "            measurements.append(data)\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"UnicodeDecodeError: Failed to decode {filename} with 'latin1' encoding.\")\n",
    "            print(e)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {filename}: {e}\")\n",
    "    return measurements\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Load measurement data\n",
    "measurements_90 = load_measurement_data(file_90, j_90, input_directory)\n",
    "measurements_173 = load_measurement_data(file_173, j_173, input_directory)\n",
    "\n",
    " \n",
    "idx = 1\n",
    "j1 = j_90\n",
    "data90 = {}\n",
    "\n",
    "while idx <= 5 and j_90 <= j1 + 4:\n",
    "    try:\n",
    "        with open(f'{file_90}{j_90}') as f:\n",
    "            fileRead = f.readlines()\n",
    "\n",
    "        start_line1 = next(i for i, line in enumerate(fileRead) if 'Correlation' in line)\n",
    "\n",
    "        data90[idx] = np.loadtxt(f'{file_90}{j_90}', delimiter=',', skiprows=start_line1)\n",
    "\n",
    "        # Getting additional info if required (similar logic as MATLAB)\n",
    "        if showHor == 1:\n",
    "            info_lines = [12, 16, 37, 38]\n",
    "            for i_info in info_lines:\n",
    "                with open(f'{file_90}{j_90}') as file_info:\n",
    "                    line_file_info = None\n",
    "                    for _ in range(i_info):\n",
    "                        line_file_info = file_info.readline()\n",
    "\n",
    "                # Extracting specific information based on line type\n",
    "                if i_info == info_lines[0]:\n",
    "                    Trans90[idx] = float(line_file_info.split(',')[1].strip())\n",
    "                elif i_info == info_lines[1]:\n",
    "                    Counts90[idx] = float(line_file_info.split(',')[1].strip())\n",
    "                elif i_info == info_lines[2]:\n",
    "                    Hor_Zav90[idx] = float(line_file_info.split(',')[1].strip())\n",
    "                elif i_info == info_lines[3]:\n",
    "                    Hor_PDI90[idx] = float(line_file_info.split(',')[1].strip())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error processing file {file_90}{j_90}: {e}')\n",
    "\n",
    "    idx += 1\n",
    "    j_90 += 1\n",
    "\n",
    "idx = 1\n",
    "j1 = j_173\n",
    "data173 = {}\n",
    "\n",
    "while idx <= 5 and j_173 <= j1 + 4:\n",
    "    try:\n",
    "        with open(f'{file_173}{j_173}') as f:\n",
    "            fileRead = f.readlines()\n",
    "\n",
    "        start_line1 = next(i for i, line in enumerate(fileRead) if 'Correlation' in line)\n",
    "\n",
    "        data173[idx] = np.loadtxt(f'{file_173}{j_173}', delimiter=',', skiprows=start_line1)\n",
    "\n",
    "        # Getting additional info if required (similar logic as MATLAB)\n",
    "        if showHor == 1:\n",
    "            info_lines = [12, 16, 37, 38]\n",
    "            for i_info in info_lines:\n",
    "                with open(f'{file_173}{j_173}') as file_info:\n",
    "                    line_file_info = None\n",
    "                    for _ in range(i_info):\n",
    "                        line_file_info = file_info.readline()\n",
    "\n",
    "                # Extracting specific information based on line type\n",
    "                if i_info == info_lines[0]:\n",
    "                    Trans173[idx] = float(line_file_info.split(',')[1].strip())\n",
    "                elif i_info == info_lines[1]:\n",
    "                    Counts173[idx] = float(line_file_info.split(',')[1].strip())\n",
    "                elif i_info == info_lines[2]:\n",
    "                    Hor_Zav173[idx] = float(line_file_info.split(',')[1].strip())\n",
    "                elif i_info == info_lines[3]:\n",
    "                    Hor_PDI173[idx] = float(line_file_info.split(',')[1].strip())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error processing file {file_173}{j_173}: {e}')\n",
    "\n",
    "    idx += 1\n",
    "    j_173 += 1\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists or dictionaries to store results\n",
    "lag90 = {}\n",
    "corr90a = {}\n",
    "F90 = {}\n",
    "X90 = {}\n",
    "Res90 = {}\n",
    "\n",
    "# Initialize lists or dictionaries to store results\n",
    "lag173 = {}\n",
    "corr173a = {}\n",
    "F173= {}\n",
    "X173 = {}\n",
    "Res173 = {}\n",
    "\n",
    "# Autocorrelation curves fitting at 90°\n",
    "for idx in range(1, 6):\n",
    "    try:\n",
    "        lag90[idx] = data90[idx][:, 0] / 1e3  # Transform time units to milliseconds\n",
    "        corr90a[idx] = data90[idx][:, 1]\n",
    "\n",
    "        if NormLz == 1:\n",
    "            for idx1 in range(len(corr90a)):\n",
    "                corr90a[idx1] = corr90a[idx1] / np.mean(corr90a[idx1][:3])  # Normalize by mean of first 3 values\n",
    "\n",
    "        xdata = lag90[idx]\n",
    "        ydata = corr90a[idx]\n",
    "\n",
    "        q_square_temp = (((4 * np.pi * rIndex / lambda_val) * np.sin((90 * np.pi / 180) / 2))**2)\n",
    "        x0_g = x0_1.copy()\n",
    "        lb_g = lb_1.copy()\n",
    "        up_g = up_1.copy()\n",
    "        x0_g[2] = 0.001 * q_square_temp * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * x0_1[2])\n",
    "        lb_g[2] = 0.001 * q_square_temp * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * up_1[2])\n",
    "        up_g[2] = 0.001 * q_square_temp * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * lb_1[2])\n",
    "\n",
    "        # Define cumulantDLS function\n",
    "        def cumulantDLS(x, xdata):\n",
    "            return x[0] + x[1] * (np.exp(-x[2] * xdata) * (1 + 0.5 * x[3] * xdata**2))**2\n",
    "\n",
    "        # Perform curve fitting\n",
    "        x, resnormS, residuals = lsqcurvefit(cumulantDLS, x0_g, xdata, ydata, lb_g, up_g)\n",
    "        F90[idx] = cumulantDLS(x, xdata)\n",
    "        X90[idx] = x\n",
    "        Res90[idx] = residuals\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error fitting autocorrelation curve at 90° for idx={idx}: {e}')\n",
    "\n",
    "# Autocorrelation curves fitting at 173°\n",
    "for idx in range(1, 6):\n",
    "    try:\n",
    "        lag173[idx] = data173[idx][:, 0] / 1e3  # Transform time units to milliseconds\n",
    "        corr173a[idx] = data173[idx][:, 1]\n",
    "\n",
    "        if NormLz == 1:\n",
    "            for idx1 in range(len(corr173a)):\n",
    "                corr173a[idx1] = corr173a[idx1] / np.mean(corr173a[idx1][:3])  # Normalize by mean of first 3 values\n",
    "\n",
    "        xdata = lag173[idx]\n",
    "        ydata = corr173a[idx]\n",
    "\n",
    "        q_square_temp = (((4 * np.pi * rIndex / lambda_val) * np.sin((173 * np.pi / 180) / 2))**2)\n",
    "        x0_g = x0_1.copy()\n",
    "        lb_g = lb_1.copy()\n",
    "        up_g = up_1.copy()\n",
    "        x0_g[2] = 0.001 * q_square_temp * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * x0_1[2])\n",
    "        lb_g[2] = 0.001 * q_square_temp * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * up_1[2])\n",
    "        up_g[2] = 0.001 * q_square_temp * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * lb_1[2])\n",
    "\n",
    "        # Define cumulantDLS function\n",
    "        def cumulantDLS(x, xdata):\n",
    "            return x[0] + x[1] * (np.exp(-x[2] * xdata) * (1 + 0.5 * x[3] * xdata**2))**2\n",
    "\n",
    "        # Perform curve fitting\n",
    "        x, resnormS, residuals = lsqcurvefit(cumulantDLS, x0_g, xdata, ydata, lb_g, up_g)\n",
    "        F173[idx] = cumulantDLS(x, xdata)\n",
    "        X173[idx] = x\n",
    "        Res173[idx] = residuals\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error fitting autocorrelation curve at 173° for idx={idx}: {e}')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X90 and X173 are already defined with results from cumulantDLS fitting\n",
    "# Initialize lists or dictionaries to store results\n",
    "angle = np.zeros(len(X90) + len(X173))\n",
    "G1 = np.zeros(len(X90) + len(X173))\n",
    "Baseline = np.zeros(len(X90) + len(X173))\n",
    "Amplitude = np.zeros(len(X90) + len(X173))\n",
    "variance = np.zeros(len(X90) + len(X173))\n",
    "\n",
    "# Get angles automatically\n",
    "for angle_idx_1 in range(len(X90)):\n",
    "    angle[angle_idx_1] = 90\n",
    "\n",
    "for angle_idx_2 in range(len(X173)):\n",
    "    angle[len(X90) + angle_idx_2] = 173\n",
    "\n",
    "angle_deg = angle\n",
    "angle = angle * np.pi / 180\n",
    "q = (4 * np.pi * rIndex / lambda_val) * np.sin(angle / 2)\n",
    "q_square = q**2\n",
    "\n",
    "# Get G1 and other parameters automatically\n",
    "for angle_idx_1 in range(len(X90)):\n",
    "    G1[angle_idx_1] = X90[angle_idx_1][2]\n",
    "    Baseline[angle_idx_1] = X90[angle_idx_1][0]\n",
    "    Amplitude[angle_idx_1] = X90[angle_idx_1][1]\n",
    "    variance[angle_idx_1] = X90[angle_idx_1][3]\n",
    "\n",
    "for angle_idx_2 in range(len(X173)):\n",
    "    G1[len(X90) + angle_idx_2] = X173[angle_idx_2][2]\n",
    "    Baseline[len(X90) + angle_idx_2] = X173[angle_idx_2][0]\n",
    "    Amplitude[len(X90) + angle_idx_2] = X173[angle_idx_2][1]\n",
    "    variance[len(X90) + angle_idx_2] = X173[angle_idx_2][3]\n",
    "\n",
    "# Now you can use angle, G1, Baseline, Amplitude, variance as needed\n",
    "\n",
    "# Initialize dictionaries to store additional results\n",
    "G2 = {}\n",
    "\n",
    "# Calculate G2 and other parameters automatically\n",
    "for angle_idx_1 in range(len(X90)):\n",
    "    # Assuming you have already defined the necessary parameters like q_square, Boltzmann, Temp_Kelvin, visc\n",
    "    G2[angle_idx_1] = 0.001 * q_square[angle_idx_1] * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * G1[angle_idx_1])\n",
    "\n",
    "for angle_idx_2 in range(len(X173)):\n",
    "    G2[len(X90) + angle_idx_2] = 0.001 * q_square[len(X90) + angle_idx_2] * Boltzmann * Temp_Kelvin / (3 * np.pi * visc * G1[len(X90) + angle_idx_2])\n",
    "\n",
    "# FIT diffusion coefficient\n",
    "xdata1 = q_square\n",
    "ydata1 = G1\n",
    "\n",
    "xdata1[Discard_list] = []\n",
    "ydata1[Discard_list] = []\n",
    "\n",
    "x0 = 2e-14\n",
    "x, resnormS1 = lsqcurvefit(linear0, x0, xdata1, ydata1)\n",
    "fit1 = linear0(x, xdata1)\n",
    "\n",
    "D1 = x * 1000  # Convert to m^2/s\n",
    "Rh1 = (Boltzmann * Temp_Kelvin) / (6 * np.pi * visc * D1)\n",
    "Dh1 = Rh1 * 2\n",
    "\n",
    "R2_1 = 1 - resnormS1 / np.sum(ydata1**2)\n",
    "SE_D1 = 1000 * np.sqrt(resnormS1 / (len(ydata1) - 1)) / np.sqrt(np.sum(xdata1**2))\n",
    "SE_Rh1 = (SE_D1 / D1) * Rh1\n",
    "SE_Dh1 = (SE_D1 / D1) * Dh1\n",
    "\n",
    "# Calculate individual D and Dh\n",
    "D1_indiv = 1000 * G1 / q_square  # m^2 / s\n",
    "D2_indiv = 1000 * G2 / q_square  # m^2 / s\n",
    "\n",
    "Dh1_indiv = 10**9 * (Boltzmann * Temp_Kelvin) / (3 * np.pi * visc * D1_indiv)  # m\n",
    "Dh2_indiv = 10**9 * (Boltzmann * Temp_Kelvin) / (3 * np.pi * visc * D2_indiv)  # m\n",
    "\n",
    "if np.sum(G2 == 0) != 0:\n",
    "    D3_indiv = 1000 * G1[G2 == 0] / q_square[G2 == 0]  # m^2 / s\n",
    "    Dh3_indiv = 10**9 * (Boltzmann * Temp_Kelvin) / (3 * np.pi * visc * D3_indiv)  # m\n",
    "\n",
    "\n",
    "\n",
    "# Calculate PDI table\n",
    "PDI_table = variance / (G1**2)\n",
    "PDI_valid = PDI_table.copy()\n",
    "PDI_valid = np.delete(PDI_valid, Discard_list)\n",
    "mean_PDI = np.mean(PDI_valid[PDI_valid != 0])\n",
    "\n",
    "# Prepare PDI for 90° and 173° angles\n",
    "PDI_90 = PDI_table[:len(X90)]\n",
    "PDI_90_valid = PDI_90.copy()\n",
    "PDI_90_valid = np.delete(PDI_90_valid, Discard_list_1)\n",
    "mean_PDI_90 = np.mean(PDI_90_valid[PDI_90_valid != 0])\n",
    "\n",
    "PDI_173 = PDI_table[len(X90):len(X173) + len(X90)]\n",
    "PDI_173_valid = PDI_173.copy()\n",
    "PDI_173_valid = np.delete(PDI_173_valid, Discard_list_2 - len(X90))\n",
    "mean_PDI_173 = np.mean(PDI_173_valid[PDI_173_valid != 0])\n",
    "\n",
    "std_PDI_valid = 0.5 * np.sqrt((np.std(PDI_173_valid))**2 + (np.std(PDI_90_valid))**2)\n",
    "std_PDI_90_valid = np.std(PDI_90_valid)\n",
    "std_PDI_173_valid = np.std(PDI_173_valid)\n",
    "\n",
    "# Prepare FitResultsTable\n",
    "FitResultsTable = np.column_stack((angle_deg, Amplitude, G1, Dh1_indiv, variance, PDI_table, Baseline))\n",
    "print(' Fitting Results using the Cumulants analysis ')\n",
    "print('        angle      amplitude    Gamma1 /ms-1 Dh_ind /m   variance    PDI        baseline ')\n",
    "\n",
    "# Remove rows specified by Discard_list_total\n",
    "FitResultsTable = np.delete(FitResultsTable, Discard_list_total, axis=0)\n",
    "\n",
    "# Print the final FitResultsTable\n",
    "print(FitResultsTable)\n",
    "\n",
    "# Define the color map (cmap1 and cmap2) as RGB values\n",
    "cmap1 = np.array([[0, 0, 1], [0, 0.75, 0], [1, 0, 0], [0.5, 0, 1], [1, 0.5, 0], [0, 0, 0], [0.5, 0.5, 0.5], [0.5, 0.25, 0.1]])\n",
    "cmap2 = cmap1\n",
    "\n",
    "# Plotting Figure 1\n",
    "fig1, ax1 = plt.subplots()\n",
    "plot_list_90 = [i for i in range(len(X90)) if i not in Discard_list_total_1]\n",
    "plot_list_173 = [i for i in range(len(X173)) if i not in Discard_list_total_2 - len(X90)]\n",
    "\n",
    "for idx in plot_list_90:\n",
    "    if idx in Discard_list:\n",
    "        ax1.semilogx(lag90[idx], corr90a[idx], '-', color=[0.5, 0.5, 0.5], linewidth=1.5)\n",
    "    else:\n",
    "        ax1.semilogx(lag90[idx], F90[idx], '-', color=cmap1[idx], linewidth=1.5)\n",
    "        ax1.semilogx(lag90[idx], corr90a[idx], 'o', markersize=5, markeredgewidth=1, markeredgecolor='black', markerfacecolor=cmap1[idx])\n",
    "\n",
    "for idx in plot_list_173:\n",
    "    if idx + len(plot_list_90) in Discard_list:\n",
    "        ax1.semilogx(lag173[idx], F173[idx], '-', color=[0.5, 0.5, 0.5], linewidth=1.5)\n",
    "    else:\n",
    "        ax1.semilogx(lag173[idx], F173[idx], '-', color=cmap2[idx], linewidth=1.5)\n",
    "        ax1.semilogx(lag173[idx], corr173a[idx], 's', markersize=5, markeredgewidth=1, markeredgecolor='black', markerfacecolor=cmap1[idx])\n",
    "\n",
    "# Set labels and ticks\n",
    "ax1.set_xlabel(r'$\\tau$ / ms', fontsize=11)\n",
    "ax1.set_ylabel(r'$G_2(\\tau) - 1$', fontsize=11)\n",
    "ax1.set_xlim([0.5e-3, 2e2])\n",
    "ax1.set_xticks([1e-3, 1e-2, 1e-1, 1, 10, 100])\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.tick_params(axis='both', which='both', direction='inout', labelsize=10)\n",
    "\n",
    "# Adding legend and text on figure\n",
    "if showLegd == 1:\n",
    "    ax1.legend(['circles: 90Ί', 'fit', 'B', 'fit', 'C', 'fit', 'D', 'fit', 'squares: 173Ί', 'fit', 'F', 'fit', 'G', 'fit', 'H', 'fit', 'I', 'fit', 'J', 'fit', 'K', 'fit', 'L', 'fit'])\n",
    "\n",
    "if showPartSize == 1:\n",
    "    ax1.text(0.8e-3, 0.21, f'D_H = {2 * Rh1 * 10**9:.0f} nm', fontsize=6, color='b', horizontalalignment='left')\n",
    "\n",
    "# Saving Figure 1\n",
    "if PrintFigs == 1:\n",
    "    fig1.savefig('temp1.tif', dpi=600)\n",
    "\n",
    "# Plotting Figure 2\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "# Set the new default color order cmap2\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=cmap2)\n",
    "\n",
    "# Plot data according to FitModel == 1\n",
    "ax2.plot(q_square, G1, 'o', markersize=5, markeredgewidth=1, markeredgecolor=[0.5, 0.5, 0.5], markerfacecolor=[0.5, 0.5, 0.5])\n",
    "ax2.plot(xdata, ydata, 'o', markersize=5, markeredgewidth=1, markeredgecolor=[0, 0, 1], markerfacecolor=[0, 0, 1])\n",
    "ax2.plot([0, xdata], [0, fit1], '-', color=[0, 0.9, 0])\n",
    "\n",
    "# Set labels and ticks for Figure 2\n",
    "ax2.set_xlabel(r'$q^2 / m^{-2}$', fontsize=11)\n",
    "ax2.set_ylabel(r'$\\Gamma / ms^{-1}$', fontsize=11)\n",
    "ax2.tick_params(axis='both', which='both', direction='inout', labelsize=10)\n",
    "\n",
    "# Adding text on Figure 2\n",
    "if showR2 == 1:\n",
    "    ax2.text(0.5, ax2.get_ylim()[1] - 1.2, f'R^2 = {R2_1:.3f}; N = {len(xdata)}; D_h_1 = {Dh1 * 10**9:.1f} ± {SE_Dh1 * 10**9:.1f} nm', fontsize=5, color=[0, 0.9, 0], horizontalalignment='left')\n",
    "    ax2.text(0.5, ax2.get_ylim()[1] - 1.7, f'Dif_1 = {D1:.3f} ± {SE_D1:.3f} m^2/s', fontsize=5, color=[0, 0.9, 0], horizontalalignment='left')\n",
    "\n",
    "# Saving Figure 2\n",
    "if PrintFigs == 1:\n",
    "    fig2.savefig('temp2.tif', dpi=600)\n",
    "\n",
    "# Merging figures if mergeFigs == 1 (not implemented in Python, you may need additional libraries for image processing)\n",
    "# Save Figures\n",
    "if PrintFigs == 1:\n",
    "    fig1.savefig(output_directory + 'temp1.tif', dpi=600)\n",
    "    fig2.savefig(output_directory + 'temp2.tif', dpi=600)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SapalSAXS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
